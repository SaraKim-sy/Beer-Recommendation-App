# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/175-L45EVo68JJCbgWSPsNlbIglyw-lU6

## Clean up your data
The beer data collected includes beers with atleast 1 review from the users.
We build a dataset (final_data.csv) of only beer and users with at least 10 reviews.
The algorithm to be used to implement the recommendation system is item-based CF.

**Collaborative filtering (CF)** is divided into nearest neighbor collaborative filtering and latent factor collaborative filtering.

And the nearest neighbor collaborative filtering is again divided into user-based and item-based.

Among them, the reasons for choosing item-based are as follows.

1.  The individual tastes of users are too diverse.
2.  On the other hand, the number of beer users leaving a review is limited.

Therefore, we decided that it is appropriate to recommend it on an item basis.
"""

import pandas as pd
import numpy as np
import os
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error

import warnings

warnings.filterwarnings('ignore')

# User who left more than n data reviews, a function to filter beer
def preprocessing(data, n):
    min_id = data['user'].value_counts() >= n
    min_id = min_id[min_id].index.to_list()
    data = data[data['user'].isin(min_id)]

    min_beer = data['beer_name'].value_counts() >= n
    min_beer = min_beer[min_beer].index.to_list()
    data = data[data['beer_name'].isin(min_beer)]

    return data

tmp = pd.read_csv("final_data.csv",encoding= 'unicode_escape')
temp=tmp.copy()

# Repeat 10 times.
for i in range(1,10):
    temp = preprocessing(temp, 10)
    print(temp.shape)

temp.to_csv('Refined_data.csv', encoding='utf-8')

"""The existing data was about 91,776, but it is now reduced to 57,013.

## **Recommendation based on similarity between beer**
We will now recommend similar beers based on the similarity between beers.

The criterion for measuring similarity was **Cosine similarity** and **Pearson similarity**.

Pearson similarity is used when too large or too small a value significantly affects the similarity.

Also, there was no outlier in the EDA process and we confirmed that the ratings also follow a normal distribution. Therefore, we decided to use cosine similarity.

Among the refined data, the matrix is ​​composed of 3 columns necessary for the implementation of the recommendation system.

The three factors are **User, Beer Name, and Rating.**
"""

data = pd.read_csv('Refined_data.csv', encoding='utf-8', index_col=0)

ratings = data.copy()

# Construct a user-ID matrix using a pivot table
ratings_matrix = ratings.pivot_table('rating', index='user', columns='beer_name')
ratings_matrix.head(3)
# Nan processing using fillna function
ratings_matrix = ratings_matrix.fillna(0)
ratings_matrix

# Transpose for similarity calculation
ratings_matrix_T = ratings_matrix.transpose()
ratings_matrix_T

# Finding cosine similarity from item-user matrix
item_sim = cosine_similarity(ratings_matrix_T, ratings_matrix_T)

# Convert the beer name to a DataFrame by mapping the beer name to the NumPy matrix returned by cosine_similarity()
item_sim_df = pd.DataFrame(data=item_sim, index=ratings_matrix.columns,
                          columns=ratings_matrix.columns)

print(item_sim_df.shape)
item_sim_df.head(3)

# Calculated Cosine similarity above and we found that there are 82 types of beers.
ratings_matrix.columns

# Extracting only 5 beers with a similarity to Kozel Beer
item_sim_df['Kozel Cerný (Dark)'].sort_values(ascending=False)[:5]

# Extracting only 5 beers with a similarity to Hoegaarden Beer
item_sim_df['Hoegaarden Grand Cru'].sort_values(ascending=False)[:5]

"""## **Personalized beer recommendations**
Now we will implement a recommendation system that reflects the individual's rating.
"""

# ratings_arr.dot(item_sim_arr) is the rating * beer similarity
# ratings_arr is the actual rating vector for the Top_N items with the highest similarity to item i of user u.
# item_sim_arr is the similarity vector of Top_N items with the highest similarity to item i
def predict_rating(ratings_arr, item_sim_arr):
    ratings_pred = ratings_arr.dot(item_sim_arr) / np.array([np.abs(item_sim_arr).sum(axis=1)])
    return ratings_pred

# Finding a personalized prediction score
# Only the rating value and the similarity value are extracted and assigned
ratings_pred = predict_rating(ratings_matrix.values, item_sim_df.values)
ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index=ratings_matrix.index,
                                  columns = ratings_matrix.columns)

# Predicted score calculated for each individual
ratings_pred_matrix

# MSE calculates the difference between our predicted and actual ratings
def get_mse(pred, actual):
    # Extract only real movies with ratings
    pred = pred[actual.nonzero()].flatten()
    actual = actual[actual.nonzero()].flatten()
    return mean_squared_error(pred, actual)

print('Item-based All Nearest Neighbor MSEs:', 
      get_mse(ratings_pred, ratings_matrix.values))

"""## **Top-N based recommendations**

To lower the MSE value further, only the N beers that are most similar to a particular beer should be used in the similarity calculation.

The above method uses the similarity vector of all beers, so the MSE value is rather low.
"""

# Only up to 3 cols. 5 selections with high similarity for 3 beers
top_n_items = [np.argsort(item_sim_df.values[:,3])[:-5:-1]]
top_n_items

# Therefore, only beer with the most similar similarity is used as the similarity vector.
# Applies only to Beer Top_N that has similar similarity to a specific beer -> Takes a long time

def predict_rating_topsim(ratings_arr, item_sim_arr, n=20):
    # Initialize a prediction matrix filled with zeros equal to the size of the user-item rating matrix
    pred = np.zeros(ratings_arr.shape)

    # Loop as many beers in the user-item rating matrix
    for col in range(ratings_arr.shape[1]):
        # Return the indices of n data matrices in the order of similarity in the similarity matrix
        top_n_items = [np.argsort(item_sim_arr[:, col])[:-n-1:-1]]
        # Personalized prediction score calculation: For each col beer (1 piece), the prediction score of 3015 users
        for row in range(ratings_arr.shape[0]):
            pred[row, col] = item_sim_arr[col,:][top_n_items].dot(
            ratings_arr[row, :][top_n_items].T)
            pred[row, col] /= np.sum(item_sim_arr[col,:][top_n_items])

    return pred

ratings_pred = predict_rating_topsim(ratings_matrix.values, item_sim_df.values, n=10)
print('Item-based nearest TOP-N neighbor MSE: ', 
      get_mse(ratings_pred, ratings_matrix.values))

# The calculated predicted score data is recreated as a DataFrame.
ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index=ratings_matrix.index,
                                  columns=ratings_matrix.columns)

ratings_pred_matrix

"""The MSE values ​​have decreased and the prediction matrix values ​​have also changed.

## **Recommend to real users**
Given a sample username and rating, we will recommend 3 beers.

As an example, we used user information that already exists in the matrix
"""

# username='snoworsummer(8,581)'
username='lmojoh(3,265)'

# Beer recommendation for specific users
user_rating_id = ratings_matrix.loc[username, :]
# Print the beer that the user ate
user_rating_id[user_rating_id > 0].sort_values(ascending=False)[:10]

# Recommend a beer that users haven't tasted.
def get_not_tried_beer(ratings_matrix, userId):
    # Extracts all beer information of the user entered as userId and returns it to Series
    # The returned user_rating is a Series object with the userid as an index.
    user_rating = ratings_matrix.loc[userId, :]

    # If user_rating is greater than 0, it is related to the existing movie.
    # Extract target index and make list object
    tried = user_rating[user_rating>0].index.tolist()

    # Make all beer names into list objects
    beer_list = ratings_matrix.columns.tolist()

    # Movies corresponding to tried as a list comprehension are excluded from beer_list
    not_tried = [beer for beer in beer_list if beer not in tried]

    return not_tried

# After extracting the user id index and the beer name entered as not_tried from the predicted rating DataFrame
# Sort by highest predicted rating
def recomm_beer_by_userid(pred_df, userId, not_tried, top_n):
    recomm_beer = pred_df.loc[userId, not_tried].sort_values(ascending=False)[:top_n]
    return recomm_beer

# Extracting the beer name that the user has not eaten
not_tried = get_not_tried_beer(ratings_matrix, username)
not_tried

"""### Finally, we recommend beer with item-based nearest neighbor CF."""

# Only beers similar to top_n are used for recommendations
ratings_pred = predict_rating_topsim(ratings_matrix.values, item_sim_df.values, n=5)

# The calculated predicted score data is recreated as a DataFrame.
ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index=ratings_matrix.index,
                                   columns=ratings_matrix.columns)

# Extracting the beer name that the user has not eaten
not_tried = get_not_tried_beer(ratings_matrix, username)

# Recommended beer as an item-based nearest neighbor CF
recomm_beer = recomm_beer_by_userid(ratings_pred_matrix, username, not_tried, top_n=3)
recomm_beer = pd.DataFrame(data=recomm_beer.values, index=recomm_beer.index,
                           columns=['Prediction_Score'])
recomm_beer